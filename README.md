# SPORT Lab Research Summary and Reports

This GitHub repository is dedicated to hosting summaries, presentations, and status reports related to my role as a Graduate Research Assistant at the System Power Optimization and Regulation Technology (SPORT) Lab, University of Southern California. The aim is to provide an insight into the methodologies, tools, and technologies I've been working with, without divulging any proprietary or sensitive information pertaining to SPORT Lab's research.

## üìÖ Timeline of Experience

**April 2023 - Present**

## üìç Location

Los Angeles, California, United States (On-site)

## üìù Repository Contents

- **Summaries:** Concise overviews of completed tasks and milestones achieved in the research.
- **Presentations:** Non-proprietary slides and materials used for internal and external knowledge sharing.
- **Status Reports:** Regular updates on the progress of ongoing projects and tasks.

## üö´ Non-Disclosure Notice

All content in this repository is curated to respect the confidentiality agreement with SPORT Lab. Proprietary algorithms, specific data, and sensitive technology details have been excluded.

## üõ† Skills & Expertise

- **Languages & Frameworks:** PyTorch, C++, Python, TensorFlow
- **Specializations:** Compiler Optimization, Machine Learning, Artificial Neural Networks, Deep Neural Networks (DNN), AI, Convolutional Neural Networks (CNN)
- **Tools & Technologies:** NLP, LLMs, Transformers, OpenCV

## üéØ Roles and Responsibilities at SPORT Lab

- **Integration of Transformer Models with DNN Compilers:** Pioneered research in merging transformer models with deep neural network compilers, contributing significantly to neural network optimization and deployment.
- **Specialized Hardware Design for DNN Accelerators:** Played a key role in designing hardware focusing on parallelism, memory hierarchy, and energy efficiency, which are crucial for optimizing DNN computations.
- **Development of Reduced-Memory-Access Inference Compiler:** Authored and maintained significant codebases in Python and C++, enhancing system performance and efficiency.
- **Compiler Architecture Optimization:** Worked on graph optimization, code generation, and mapping neural network models to the accelerator architecture, resulting in a notable increase in compiler speed.
- **Testing and Validation:** Implemented rigorous testing protocols to ensure the reliability and performance of DNN accelerators and compilers.
- **Algorithm Development for Resource-Constrained Platforms:** Developed efficient algorithms for platforms with limited resources, focusing on computational efficiency and reduced memory usage.
- **Deep Learning Model Extensions:** Engineered custom operators to expand the functionality of deep learning models, including converting high-level models into efficient intermediate representations.
- **Integration of TVM Compiler:** Successfully integrated the TVM deep learning compiler into the lab's workflow, facilitating a robust hybrid compiler system.
- **Deployment Acceleration:** Enhanced deployment times through scripting tools for generating HDL files, leading to a 30% improvement in deployment times.
- **Documentation and Codebase Maintenance:** Authored detailed documentation for design, implementation, and testing, ensuring clarity and maintainability of the project.

## üìà Impact and Achievements

- Enhanced neural network optimization and deployment through innovative research and development.
- Authored and maintained a large codebase, significantly contributing to the advancement of SPORT Lab's proprietary technologies.
- Improved computational efficiency and system performance through various optimizations and innovations.
- Spearheaded the development of a hybrid compiler system, demonstrating adeptness in both hardware and software aspects of AI and ML.

## üì´ Contact

- Email: ssomashe@usc.edu ; ssuhas.28@gmail.com
- LinkedIn: https://www.linkedin.com/in/ssuhass/
- Phone: +1 213-(691)-3808

